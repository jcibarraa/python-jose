{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53bb7f4-f187-4b7c-aec9-6e0332947635",
   "metadata": {},
   "source": [
    "# Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c15d5b3-edc7-402e-8257-e2eaa734809a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f49810-90d4-4892-b838-a2a6fa5e2eab",
   "metadata": {},
   "source": [
    "# Definios el rango de las pruebas y los arrays para las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a441394-f59e-4a4a-a809-565abdb1b029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeros_prueba = range(0,10)\n",
    "imagenes = []\n",
    "etiquetas_imagenes = []\n",
    "\n",
    "num = 0\n",
    "guardar = str()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf0e63-99e2-4ca1-9124-f3f304b9d239",
   "metadata": {},
   "source": [
    "# Aplanamos las imagenes en un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb71e00-df77-40bd-950d-6e6e0ba75323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#0.28 0.28 0,1       0.28 29.56 0,2\n",
    "for number in numeros_prueba:\n",
    "    imgReaded= f'{str(number)}grilla.jpg'\n",
    "    img = cv2.imread(imgReaded, cv2.IMREAD_GRAYSCALE)\n",
    "    for i in range(0,280*11,28):\n",
    "        ini_ver = i \n",
    "        fin_ver = i+27\n",
    "        for j in range (0,280,28):\n",
    "            ini_hor = j\n",
    "            fin_hor = j+27\n",
    "            #num+=1\n",
    "            #guardar = str(num)+\".jpg\"\n",
    "            img_numero = img[ini_ver:fin_ver, ini_hor:fin_hor].copy()\n",
    "            img_numero = cv2.resize(img_numero, (28, 28))\n",
    "            imagenes.append(img_numero)\n",
    "            etiquetas_imagenes.append(number)\n",
    "            #cv2.imwrite(guardar ,img[ini_ver:fin_ver, ini_hor:fin_hor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7314857c-4fc7-4c8e-84ed-bc19c4fdfbd5",
   "metadata": {},
   "source": [
    "# Establecemos los arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c868a8d-40e0-4398-a13b-0e696d708152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagenes = np.array(imagenes)\n",
    "etiquetas_imagenes = np.array(etiquetas_imagenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ac97d-e864-4a38-88d5-0a32ddd7cb39",
   "metadata": {},
   "source": [
    "# Definimos el modelo de la red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6798ba9-9798-49cb-ba30-02e89c50e043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), # Capa de entrada que aplana las imágenes de 28x28 píxeles a un vector de 784 elementos\n",
    "\n",
    "    tf.keras.layers.Dense(1545, activation='relu'), # Capa oculta con x neuronas y función de activación ReLU\n",
    "    #tf.keras.layers.Dropout(0.2), # Regularización mediante el uso de una capa de Dropout\n",
    "\n",
    "    #tf.keras.layers.Dense(850, activation='relu'), \n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    #tf.keras.layers.Dense(550, activation='relu'), \n",
    "    #tf.keras.layers.Dropout(0.2), \n",
    "    \n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa70bdb-291e-45a7-8054-12885eba8bb3",
   "metadata": {},
   "source": [
    "# Complilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4eeeec-c2e6-4f42-a1c5-16537f7d7bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b583a8-2bd8-46cd-8b51-67b309542770",
   "metadata": {},
   "source": [
    "# Ajustar el modelo a las imágenes de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f920e637-3c6e-438a-86c9-308cc355b455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "344/344 [==============================] - 7s 18ms/step - loss: 99.4502 - accuracy: 0.5932\n",
      "Epoch 2/10\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 3.5490 - accuracy: 0.7101\n",
      "Epoch 3/10\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 1.2589 - accuracy: 0.6705\n",
      "Epoch 4/10\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.9448 - accuracy: 0.7044\n",
      "Epoch 5/10\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.8952 - accuracy: 0.7094\n",
      "Epoch 6/10\n",
      "344/344 [==============================] - 6s 17ms/step - loss: 0.7751 - accuracy: 0.7558\n",
      "Epoch 7/10\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.8106 - accuracy: 0.7375\n",
      "Epoch 8/10\n",
      "344/344 [==============================] - 7s 20ms/step - loss: 0.6921 - accuracy: 0.7726\n",
      "Epoch 9/10\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.6750 - accuracy: 0.7788\n",
      "Epoch 10/10\n",
      "344/344 [==============================] - 6s 18ms/step - loss: 0.6323 - accuracy: 0.7964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a829525b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(imagenes, etiquetas_imagenes, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19efdb3a-c6f3-48ed-ae45-47b79c302de0",
   "metadata": {},
   "source": [
    "# Resultados del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b79e8a2-46e8-4948-83a4-88669a09ec10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 1s 3ms/step - loss: 0.7115 - accuracy: 0.7624\n",
      "Pérdida en el conjunto de prueba: 0.7114700078964233\n",
      "Precisión en el conjunto de prueba: 0.762363612651825\n"
     ]
    }
   ],
   "source": [
    "resultado = modelo.evaluate(imagenes, etiquetas_imagenes)\n",
    "print('Pérdida en el conjunto de prueba:', resultado[0])\n",
    "print('Precisión en el conjunto de prueba:', resultado[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47262a3-43af-4cf1-98a0-98245f0a78d2",
   "metadata": {},
   "source": [
    "# Verificamos las predicciones del modelo con el numero real para ver si acepto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2538f8f4-03f6-4872-833a-c8fc38e56212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 1\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "El número predicho es: 5\n",
      "Real: 3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "El número predicho es: 5\n",
      "Real: 8\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "El número predicho es: 5\n",
      "Real: 6\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "El número predicho es: 5\n"
     ]
    }
   ],
   "source": [
    "print('Real: 1')\n",
    "img_nueva = cv2.imread(\"1prueba.jpg\", 0)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# convertir la imagen a un tensor y normalizar los valores de píxeles\n",
    "#img_prueba = tf.keras.utils.normalize(img_nueva.reshape((1, 28, 28, 1)), axis=1)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 28, 28)\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)\n",
    "\n",
    "print('Real: 3')\n",
    "\n",
    "img_nueva = cv2.imread(\"4grilla.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255.0\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 784)\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)\n",
    "\n",
    "print('Real: 8')\n",
    "\n",
    "img_nueva = cv2.imread(\"8prueba.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255.0\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 784)\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)\n",
    "\n",
    "print('Real: 6')\n",
    "\n",
    "img_nueva = cv2.imread(\"6prueba.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255.0\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 784)\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
